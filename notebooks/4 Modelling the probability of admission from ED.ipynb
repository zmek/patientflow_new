{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict ED admission probability\n",
    "\n",
    "This notebook demonstrates the first stage of prediction, to generate a probability of admission for each patient in the ED. \n",
    "\n",
    "As one of the modelling decisions is to send predictions at specified times of day, we tailor the models to these times and train one model for each time. The dataset used for this modelling is derived from snapshots of visits at each time of day. The times of day are define in config.json file in the root directory of this repo. \n",
    "\n",
    "A patient episode (visit) may well span more than one of these times, so we need to consider how we will deal with the occurence of multiple snapshots per episode. At each of these times of day, we will use only one training sample from each hospital episode.\n",
    "\n",
    "Separation of the visits into training, validation and test sets will be done chronologically into a training, validation and test set \n",
    "\n",
    "Evaluation of individual level models includes: \n",
    "- feature importance plots\n",
    "- calibration plot\n",
    "- MADCAP overall, plus breakdown by age category and length of stay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Reload functions every time\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path().home() \n",
    "USER_ROOT = Path().home() / 'work'\n",
    "\n",
    "sys.path.append(str(USER_ROOT / 'patientflow' / 'patientflow'))\n",
    "sys.path.append(str(USER_ROOT / 'patientflow' / 'functions'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/work/ed-predictor/data-raw')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file_path = USER_ROOT / 'ed-predictor' / 'trained-models'\n",
    "model_file_path\n",
    "\n",
    "data_file_path = USER_ROOT / 'ed-predictor' / 'data-raw'\n",
    "data_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameters\n",
    "\n",
    "These are set in config.json. You can change these for your own purposes. But the times of day will need to match those in the provided dataset if you want to run this notebook successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2026, 1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the times of day\n",
    "import yaml\n",
    "\n",
    "config_path = Path(USER_ROOT / 'patientflow')\n",
    "\n",
    "with open(config_path / 'config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "# Convert list of times of day at which predictions will be made (currently stored as lists) to list of tuples\n",
    "prediction_times = [tuple(item) for item in config['prediction_times']]\n",
    "\n",
    "# See the times of day at which predictions will be made\n",
    "prediction_times\n",
    "\n",
    "# Load the dates defining the beginning and end of training, validation and test sets\n",
    "start_training_set, start_validation_set, start_test_set, end_test_set = [item for item in config['modelling_dates']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ed_admissions_data_retrieval import ed_admissions_get_data\n",
    "\n",
    "csv_filename = 'ed_visits.csv'\n",
    "full_path = data_file_path / csv_filename\n",
    "\n",
    "df = ed_admissions_get_data(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snapshot_date'] = pd.to_datetime(df['snapshot_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030-03-30\n",
      "2032-04-30\n"
     ]
    }
   ],
   "source": [
    "# print start and end dates\n",
    "print(df.snapshot_date.min())\n",
    "print(df.snapshot_date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many visits there are at each time of day in the dataset. We see that number of visits represented is greater in the afternoon and evening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction_time\n",
      "(15, 30)    72563\n",
      "(12, 0)     64073\n",
      "(22, 0)     59358\n",
      "(9, 30)     46081\n",
      "(6, 0)      29436\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.prediction_time.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will confirm that the dataset aligns with the specified times of day set in the parameters file config.yaml. That is because, later, we will use these times of day to evaluate the predictions. The evaluation will fail if the data loaded does not match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Times of day at which predictions will be made\n",
      "[(6, 0), (9, 30), (12, 0), (15, 30), (22, 0)]\n",
      "\n",
      "Number of rows in dataset that are not in these times of day\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTimes of day at which predictions will be made\")\n",
    "print(prediction_times)\n",
    "print(\"\\nNumber of rows in dataset that are not in these times of day\")\n",
    "print(len(df[~df.prediction_time.isin(prediction_times)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set an index column in df\n",
    "\n",
    "Setting the index as the snapshot_id before subsetting means that we retain the same values of snapshot_id throughout the entire process, ensuring that they are consistent across the original dataset df and the training, validation and test subsets of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>visit_number</th>\n",
       "      <th>training_validation_test</th>\n",
       "      <th>elapsed_los_td</th>\n",
       "      <th>sex</th>\n",
       "      <th>arrival_method</th>\n",
       "      <th>current_location_type</th>\n",
       "      <th>total_locations_visited</th>\n",
       "      <th>...</th>\n",
       "      <th>latest_lab_results_K</th>\n",
       "      <th>latest_lab_results_Lac</th>\n",
       "      <th>latest_lab_results_NA</th>\n",
       "      <th>latest_lab_results_pCO2</th>\n",
       "      <th>latest_lab_results_pH</th>\n",
       "      <th>latest_lab_results_WCC</th>\n",
       "      <th>latest_lab_results_HCO3</th>\n",
       "      <th>has_consultation</th>\n",
       "      <th>is_admitted</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2030-04-09</td>\n",
       "      <td>(12, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 00:57:00</td>\n",
       "      <td>F</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>waiting</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2030-04-09</td>\n",
       "      <td>(15, 30)</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 04:27:00</td>\n",
       "      <td>F</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>majors</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>7.371</td>\n",
       "      <td>5.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2030-08-08</td>\n",
       "      <td>(15, 30)</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 08:16:00</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>majors</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6.31</td>\n",
       "      <td>7.361</td>\n",
       "      <td>5.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2030-08-03</td>\n",
       "      <td>(12, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>1 days 05:40:00</td>\n",
       "      <td>M</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>majors</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.83</td>\n",
       "      <td>7.434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2030-04-24</td>\n",
       "      <td>(12, 0)</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 01:50:00</td>\n",
       "      <td>F</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>sdec_waiting</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   snapshot_id snapshot_date prediction_time  visit_number  \\\n",
       "0            0    2030-04-09         (12, 0)             1   \n",
       "1            1    2030-04-09        (15, 30)             1   \n",
       "2            2    2030-08-08        (15, 30)             2   \n",
       "3            3    2030-08-03         (12, 0)             3   \n",
       "4            4    2030-04-24         (12, 0)             4   \n",
       "\n",
       "  training_validation_test   elapsed_los_td sex arrival_method  \\\n",
       "0                    train  0 days 00:57:00   F        Walk-in   \n",
       "1                    train  0 days 04:27:00   F        Walk-in   \n",
       "2                    train  0 days 08:16:00   M            NaN   \n",
       "3                    train  1 days 05:40:00   M        Walk-in   \n",
       "4                    train  0 days 01:50:00   F        Walk-in   \n",
       "\n",
       "  current_location_type  total_locations_visited  ...  latest_lab_results_K  \\\n",
       "0               waiting                        2  ...                   NaN   \n",
       "1                majors                        5  ...                   4.2   \n",
       "2                majors                        3  ...                   3.8   \n",
       "3                majors                        5  ...                   NaN   \n",
       "4          sdec_waiting                        4  ...                   NaN   \n",
       "\n",
       "   latest_lab_results_Lac  latest_lab_results_NA  latest_lab_results_pCO2  \\\n",
       "0                     NaN                    NaN                      NaN   \n",
       "1                     0.5                  141.0                     6.84   \n",
       "2                     0.9                  142.0                     6.31   \n",
       "3                     1.3                    NaN                     5.83   \n",
       "4                     NaN                    NaN                      NaN   \n",
       "\n",
       "   latest_lab_results_pH  latest_lab_results_WCC  latest_lab_results_HCO3  \\\n",
       "0                    NaN                     NaN                      NaN   \n",
       "1                  7.371                    5.28                      NaN   \n",
       "2                  7.361                    5.53                      NaN   \n",
       "3                  7.434                     NaN                      NaN   \n",
       "4                    NaN                     NaN                      NaN   \n",
       "\n",
       "   has_consultation  is_admitted  age_group  \n",
       "0             False        False      45-54  \n",
       "1             False        False      45-54  \n",
       "2              True        False      65-74  \n",
       "3             False        False      65-74  \n",
       "4              True        False      35-44  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the code below, the snapshot_id has been set as the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_date</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>visit_number</th>\n",
       "      <th>training_validation_test</th>\n",
       "      <th>elapsed_los_td</th>\n",
       "      <th>sex</th>\n",
       "      <th>arrival_method</th>\n",
       "      <th>current_location_type</th>\n",
       "      <th>total_locations_visited</th>\n",
       "      <th>num_obs</th>\n",
       "      <th>...</th>\n",
       "      <th>latest_lab_results_K</th>\n",
       "      <th>latest_lab_results_Lac</th>\n",
       "      <th>latest_lab_results_NA</th>\n",
       "      <th>latest_lab_results_pCO2</th>\n",
       "      <th>latest_lab_results_pH</th>\n",
       "      <th>latest_lab_results_WCC</th>\n",
       "      <th>latest_lab_results_HCO3</th>\n",
       "      <th>has_consultation</th>\n",
       "      <th>is_admitted</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snapshot_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030-04-09</td>\n",
       "      <td>(12, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 00:57:00</td>\n",
       "      <td>F</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>waiting</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030-04-09</td>\n",
       "      <td>(15, 30)</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 04:27:00</td>\n",
       "      <td>F</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>majors</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>141.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>7.371</td>\n",
       "      <td>5.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2030-08-08</td>\n",
       "      <td>(15, 30)</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 08:16:00</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>majors</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6.31</td>\n",
       "      <td>7.361</td>\n",
       "      <td>5.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>65-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030-08-03</td>\n",
       "      <td>(12, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>1 days 05:40:00</td>\n",
       "      <td>M</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>majors</td>\n",
       "      <td>5</td>\n",
       "      <td>405</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.83</td>\n",
       "      <td>7.434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>65-74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030-04-24</td>\n",
       "      <td>(12, 0)</td>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>0 days 01:50:00</td>\n",
       "      <td>F</td>\n",
       "      <td>Walk-in</td>\n",
       "      <td>sdec_waiting</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>35-44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            snapshot_date prediction_time  visit_number  \\\n",
       "snapshot_id                                               \n",
       "0              2030-04-09         (12, 0)             1   \n",
       "1              2030-04-09        (15, 30)             1   \n",
       "2              2030-08-08        (15, 30)             2   \n",
       "3              2030-08-03         (12, 0)             3   \n",
       "4              2030-04-24         (12, 0)             4   \n",
       "\n",
       "            training_validation_test   elapsed_los_td sex arrival_method  \\\n",
       "snapshot_id                                                                \n",
       "0                              train  0 days 00:57:00   F        Walk-in   \n",
       "1                              train  0 days 04:27:00   F        Walk-in   \n",
       "2                              train  0 days 08:16:00   M            NaN   \n",
       "3                              train  1 days 05:40:00   M        Walk-in   \n",
       "4                              train  0 days 01:50:00   F        Walk-in   \n",
       "\n",
       "            current_location_type  total_locations_visited  num_obs  ...  \\\n",
       "snapshot_id                                                          ...   \n",
       "0                         waiting                        2       14  ...   \n",
       "1                          majors                        5       30  ...   \n",
       "2                          majors                        3       67  ...   \n",
       "3                          majors                        5      405  ...   \n",
       "4                    sdec_waiting                        4       14  ...   \n",
       "\n",
       "             latest_lab_results_K  latest_lab_results_Lac  \\\n",
       "snapshot_id                                                 \n",
       "0                             NaN                     NaN   \n",
       "1                             4.2                     0.5   \n",
       "2                             3.8                     0.9   \n",
       "3                             NaN                     1.3   \n",
       "4                             NaN                     NaN   \n",
       "\n",
       "             latest_lab_results_NA  latest_lab_results_pCO2  \\\n",
       "snapshot_id                                                   \n",
       "0                              NaN                      NaN   \n",
       "1                            141.0                     6.84   \n",
       "2                            142.0                     6.31   \n",
       "3                              NaN                     5.83   \n",
       "4                              NaN                      NaN   \n",
       "\n",
       "             latest_lab_results_pH  latest_lab_results_WCC  \\\n",
       "snapshot_id                                                  \n",
       "0                              NaN                     NaN   \n",
       "1                            7.371                    5.28   \n",
       "2                            7.361                    5.53   \n",
       "3                            7.434                     NaN   \n",
       "4                              NaN                     NaN   \n",
       "\n",
       "             latest_lab_results_HCO3  has_consultation  is_admitted  age_group  \n",
       "snapshot_id                                                                     \n",
       "0                                NaN             False        False      45-54  \n",
       "1                                NaN             False        False      45-54  \n",
       "2                                NaN              True        False      65-74  \n",
       "3                                NaN             False        False      65-74  \n",
       "4                                NaN              True        False      35-44  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if df.index.name != 'snapshot_id':\n",
    "    df = df.set_index('snapshot_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate into training, validation and test sets\n",
    "\n",
    "As part of preparing the data, each visit has already been allocated into one of three sets - training, vaidation and test sets. This has been done chronologically, as shown by the output below. Using a chronological approach is appropriate for tasks where the model needs to be validated on unseen, future data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: train\n",
      "Number of rows: 190382\n",
      "Min Date: 2030-03-30\n",
      "Max Date: 2031-08-31\n",
      "\n",
      "Set: test\n",
      "Number of rows: 63401\n",
      "Min Date: 2031-11-01\n",
      "Max Date: 2032-04-30\n",
      "\n",
      "Set: valid\n",
      "Number of rows: 17235\n",
      "Min Date: 2031-09-01\n",
      "Max Date: 2031-10-31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for value in df.training_validation_test.unique():\n",
    "    subset = df[df.training_validation_test == value]\n",
    "    counts = subset.training_validation_test.value_counts().values[0]\n",
    "    min_date = subset.snapshot_date.min()\n",
    "    max_date = subset.snapshot_date.max()\n",
    "    print(f\"Set: {value}\\nNumber of rows: {counts}\\nMin Date: {min_date}\\nMax Date: {max_date}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.training_validation_test == 'train'].drop(columns='training_validation_test')\n",
    "valid_df = df[df.training_validation_test == 'valid'].drop(columns='training_validation_test')\n",
    "test_df = df[df.training_validation_test == 'test'].drop(columns='training_validation_test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below that some visits appear more than once in each of these sets. (No visit appears in more than one set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.visit_number.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the below patient has 35 episode slices, of which the majority are in the ED location 'OTF'. OTF refers to 'Off the Floor'. Patients can sometimes be moved to this location when paperwork is due, while in fact the patient has already left the ED. While it is tempting to remove these OTF locations, in real-time these patients would be picked up, so a model would ideally be trained on this data. Therefore we do need to include them in our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.visit_number == 68031].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a XGBoost Classifier for each time of day, and save the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load a transformer for the ML training data to turn it into a format that our ML classifier can read. This is done using a function called create_column_transformer() which called ColumnTransfomer() a standard method in scikit-learn. This function could be changed for different input\n",
    "\n",
    "The ColumnTransformer in scikit-learn is a tool that applies different transformations or preprocessing steps to different columns of a dataset in a single operation. OneHotEncoder converts categorical data into a format that can be provided to machine learning algorithms; without this, the model might interpret the categorical data as numerical, which would lead to incorrect results. With the OrdinalEncoder, categories are converted into ordered numerical values to reflect the inherent order in the age groups\n",
    "\n",
    "We can also specify a grid of hyperparameters, so that the classifier will iterate though them to find the best fitting model. \n",
    "\n",
    "We are interested in predictions at different times of day. So we will train a model for each time of day. We will filter each visit so that it only appears once in the training data. A random number has already been included in the dataset to facilitate this.\n",
    "\n",
    "We then iterate through the grid to find the best model for each time of day, keeping track of the best model and its results. \n",
    "\n",
    "The best model is saved, plus a dictionary of its metadata, including\n",
    "\n",
    "* how many visits were in training, validation and test sets\n",
    "* Area under ROC curve and log loss (performance metrics) for training (based on 5-fold cross validation), validation and test sets\n",
    "* List of features and their importances in the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for cross validation\n",
    "\n",
    "The ML models will be trained across a range of different hyperparameter options. When evaluating the best model, we will save common ML metrics (AUC and logloss) and compare each model for the best (lowest) logloss. Apply a chronological approach to the cross-validation split is appropriate for tasks where the model needs to be validated on unseen, future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    log_loss,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from joblib import dump, load\n",
    "\n",
    "from ed_admissions_utils import get_model_name, preprocess_data\n",
    "from ed_admissions_machine_learning import chronological_cross_validation, create_column_transformer, initialise_model\n",
    "\n",
    "# initialize a dict to save information about the best models for each time of day\n",
    "best_model_results_dict = {}\n",
    "\n",
    "# Specify where to save the dict and the trained models\n",
    "model_file_path = PROJECT_ROOT / 'dissemination' / 'model-output' \n",
    "\n",
    "# Option to iterate through different hyperparameters for XGBoost\n",
    "grid = {\n",
    "    'n_estimators':[30, 40, 50],\n",
    "    'subsample':[0.7,0.8,0.9],\n",
    "    'colsample_bytree': [0.7,0.8,0.9]\n",
    "}\n",
    "\n",
    "# certain columns are not used in training\n",
    "exclude_from_training_data = [\n",
    "    \"visit_number\",\n",
    "    \"snapshot_datetime\",\n",
    "    \"prediction_time\"]\n",
    "\n",
    "\n",
    "ordinal_mappings = {\n",
    "    \"age_group\": [\"0-17\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75-102\"],\n",
    "    \"latest_acvpu\": [\"A\", \"C\", \"V\", \"P\", \"U\"],\n",
    "    \"latest_manch_triage\": [\"Blue\", \"Green\", \"Yellow\", \"Orange\", \"Red\"],\n",
    "    \"latest_pain_objective\": [\"Nil\", \"Mild\", \"Moderate\", \"Severe\\\\Very Severe\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Process each time of day\n",
    "for prediction_time_ in prediction_times:\n",
    "\n",
    "    print(\"\\nProcessing :\" + str(prediction_time_))\n",
    "\n",
    "    # create a name for the model based on the time of day it is trained for\n",
    "    MODEL__ED_ADMISSIONS__NAME = get_model_name(prediction_time_)\n",
    "\n",
    "    # use this name in the path for saving best model\n",
    "    full_path = model_file_path / MODEL__ED_ADMISSIONS__NAME \n",
    "    full_path = full_path.with_suffix('.joblib')\n",
    "\n",
    "    # initialise data used for saving attributes of the model\n",
    "    best_model_results_dict[MODEL__ED_ADMISSIONS__NAME] = {}\n",
    "    best_valid_logloss = float('inf')\n",
    "    results_dict = {}\n",
    "    \n",
    "    # get visits that were in at the time of day in question and preprocess the training, validation and test sets \n",
    "    X_train, y_train = preprocess_data(train_df, prediction_time_, exclude_from_training_data)\n",
    "    X_valid, y_valid = preprocess_data(valid_df, prediction_time_, exclude_from_training_data)\n",
    "    X_test, y_test = preprocess_data(test_df, prediction_time_, exclude_from_training_data)\n",
    "    \n",
    "    # save size of each set\n",
    "    best_model_results_dict[MODEL__ED_ADMISSIONS__NAME]['train_valid_test_set_no'] = {\n",
    "        'train_set_no' : len(X_train),\n",
    "        'valid_set_no' : len(X_valid),\n",
    "        'test_set_no' : len(X_test),\n",
    "    }\n",
    "\n",
    "    # iterate through the grid of hyperparameters\n",
    "    for g in ParameterGrid(grid):\n",
    "        model = initialise_model(g)\n",
    "        \n",
    "        # define a column transformer for the ordinal and categorical variables\n",
    "        column_transformer = create_column_transformer(X_test)\n",
    "        \n",
    "        # create a pipeline with the feature transformer and the model\n",
    "        pipeline = Pipeline([\n",
    "            ('feature_transformer', column_transformer),\n",
    "            ('classifier', m)\n",
    "        ])\n",
    "\n",
    "        # cross-validate on training set using the function created earlier\n",
    "        cv_results = chronological_cross_validation(pipeline, X_train, y_train, n_splits=5)\n",
    "\n",
    "        # Store results for this set of parameters in the results dictionary\n",
    "        results_dict[str(g)] = {\n",
    "            'train_auc': cv_results['train_auc'],\n",
    "            'valid_auc': cv_results['valid_auc'],\n",
    "            'train_logloss': cv_results['train_logloss'],\n",
    "            'valid_logloss': cv_results['valid_logloss'],\n",
    "        }\n",
    "        \n",
    "        # Update and save best model if current model is better on validation set\n",
    "        if cv_results['valid_logloss'] < best_valid_logloss:\n",
    "\n",
    "            # save the details of the best model\n",
    "            best_model = str(g)\n",
    "            best_valid_logloss = cv_results['valid_logloss']\n",
    "\n",
    "            # save the best model params\n",
    "            best_model_results_dict[MODEL__ED_ADMISSIONS__NAME]['best_params'] = str(g)\n",
    "\n",
    "            # save the model metrics on training and validation set\n",
    "            best_model_results_dict[MODEL__ED_ADMISSIONS__NAME]['train_valid_set_results'] = results_dict\n",
    "\n",
    "            # score the model's performance on the test set  \n",
    "            y_test_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "            test_logloss = log_loss(y_test,y_test_pred_proba)\n",
    "        \n",
    "            best_model_results_dict[MODEL__ED_ADMISSIONS__NAME]['test_set_results'] = {\n",
    "                'test_auc' : test_auc,\n",
    "                'test_logloss' : test_logloss\n",
    "            }\n",
    "\n",
    "            # save the best features\n",
    "            # To access transformed feature names:\n",
    "            transformed_cols = pipeline.named_steps['feature_transformer'].get_feature_names_out()\n",
    "            transformed_cols = [col.split('__')[-1] for col in transformed_cols]\n",
    "            best_model_results_dict[MODEL__ED_ADMISSIONS__NAME]['best_model_features'] = {\n",
    "                    'feature_names': transformed_cols,\n",
    "                    'feature_importances': pipeline.named_steps['classifier'].feature_importances_.tolist()\n",
    "                }\n",
    "\n",
    "            # save the best model\n",
    "            dump(pipeline, full_path)\n",
    "\n",
    "# save the results dictionary      \n",
    "filename_results_dict = 'best_model_results_dict.json'\n",
    "full_path_results_dict = model_file_path / filename_results_dict\n",
    "\n",
    "with open(full_path_results_dict, 'w') as f:\n",
    "    json.dump(best_model_results_dict, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with corrected code\n",
    "for key, value in best_model_results_dict.items():\n",
    "    print(f\"Model: {key}; AUC: {round(value['test_set_results']['test_auc'],3)}; log loss {round(value['test_set_results']['test_logloss'],3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before corrected code\n",
    "for key, value in best_model_results_dict.items():\n",
    "    print(f\"Model: {key}; AUC: {round(value['test_set_results']['test_auc'],3)}; log loss {round(value['test_set_results']['test_logloss'],3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in best_model_results_dict.items():\n",
    "    print(f\"Model: {key}; AUC: {round(value['test_set_results']['test_auc'],3)}; log loss {round(value['test_set_results']['test_logloss'],3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
